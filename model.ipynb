{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import gensim\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import *\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('data_after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, X_test, y_data, y_test = train_test_split(df['text'], df['lable'], test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Count Vectors as features\n",
    "# count_vect = CountVectorizer()\n",
    "# count_vect.fit(X_data)\n",
    "# X_data_count = count_vect.transform(X_data)\n",
    "# X_test_count = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TF-IDF Vectors 1\n",
    "# tfidf_vect = TfidfVectorizer(ngram_range=(2,2))\n",
    "# tfidf_vect.fit(df['text'])\n",
    "# X_data_tfidf =  tfidf_vect.transform(X_data)\n",
    "# X_test_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data_tfidf.shape\n",
    "# #X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectors 2\n",
    "tfidf_vect_ngram = TfidfVectorizer(ngram_range=(2,2))\n",
    "tfidf_vect_ngram.fit(X_data)\n",
    "X_data_tfidf_ngram =  tfidf_vect_ngram.transform(X_data)\n",
    "X_test_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35688, 3512062)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_tfidf_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #giamchieu\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "# svd.fit(X_data_tfidf)\n",
    "# X_data_tfidf_svd = svd.transform(X_data_tfidf)\n",
    "# X_test_tfidf_svd = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_ngram = TruncatedSVD(n_components=300, random_state=42)\n",
    "# svd_ngram.fit(X_data_tfidf_ngram)\n",
    "# X_data_tfidf_ngram_svd = svd_ngram.transform(X_data_tfidf_ngram)\n",
    "# X_test_tfidf_ngram_svd = svd_ngram.transform(X_test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinhtrixahoi', 'Doisong', 'Giaitri', 'Khoahoc', 'Kinhdoanh',\n",
       "       'Phapluat', 'Sohoa', 'Suckhoe', 'Thegioi', 'Thethao'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encodering to number\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_data_n = encoder.fit_transform(y_data)\n",
    "y_test_n = encoder.fit_transform(y_test)\n",
    "encoder.classes_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, X_data, y_data, X_test, y_test, is_neuralnet=False, n_epochs=3):       \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if is_neuralnet:\n",
    "        classifier.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=n_epochs, batch_size=512)\n",
    "        val_predictions = classifier.predict(X_val)\n",
    "        test_predictions = classifier.predict(X_test)\n",
    "        val_predictions = val_predictions.argmax(axis=-1)\n",
    "        test_predictions = test_predictions.argmax(axis=-1)\n",
    "    else:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        train_predictions = classifier.predict(X_train)\n",
    "        val_predictions = classifier.predict(X_val)\n",
    "        test_predictions = classifier.predict(X_test)\n",
    "    \n",
    "    #print(\"Train accuracy: \", metrics.accuracy_score(train_predictions, y_train))    \n",
    "    #print(\"Validation accuracy: \", metrics.accuracy_score(val_predictions, y_val))\n",
    "    print(\"Test accuracy: \", metrics.accuracy_score(test_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8771575879847567\n"
     ]
    }
   ],
   "source": [
    "# #tfidf 1  k co svd\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# train_model(MultinomialNB(), X_data_tfidf, y_data, X_test_tfidf, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tfidf 1  co  svd\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# train_model(MultinomialNB(), X_data_tfidf_svd, y_data, X_test_tfidf_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf 2 k co svd\n",
    "# train_model(MultinomialNB(), X_data_tfidf_ngram, y_data, X_test_tfidf_ngram, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf 2 co svd\n",
    "#train_model(MultinomialNB(), X_data_tfidf_ngram, y_data, X_test_tfidf_ngram, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(svm.SVC(), X_data_tfidf_ngram, y_data, X_test_tfidf_ngram, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV \n",
    "  \n",
    "# # defining parameter range \n",
    "# param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "#               'gamma': [1, 0.1, 0.01, 0.001,], \n",
    "#               'kernel': ['rbf', 'poly', 'sigmoid','linear']}  \n",
    "  \n",
    "# grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3) \n",
    "# # fitting the model for grid search \n",
    "# grid.fit(X_data_tfidf_svd, y_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(svm.SVC(), X_data_tfidf_ngram, y_data, X_test_tfidf_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStopword():\n",
    "    text = []\n",
    "    with open('vnsw.txt', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for i in lines:\n",
    "        text.append(i.replace('\\n', ''))\n",
    "    \n",
    "    return text\n",
    "\n",
    "def RemoveStopword(text):\n",
    "    text = text.split(' ')\n",
    "    remove_stopword = [word for word in text if not word in GetStopword()]\n",
    "    \n",
    "    s = ''\n",
    "    for i in remove_stopword:\n",
    "        s += i + ' '\n",
    "        \n",
    "    return s\n",
    "def preprocessing(text):\n",
    "    text = RemoveStopword(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['Hai cầu nối Khu đô thị mới Thủ Thiêm có tên mới','Địa danh Ba Son và Thủ Thiêm được đặt tên cho hai cầu vượt sông Sài Gòn nối trung tâm thành phố với Khu đô thị Thủ Thiêm, sáng 14/6.',\n",
    "'Cầu Thủ Thiêm 2 kết nối đường Tôn Đức Thắng (quận 1) đến khu đô thị mới được đặt tên Ba Son. Đây là công trình biểu tượng của TP HCM, khánh thành hồi tháng 4 năm ngoái với tổng vốn gần 3.100 tỷ đồng - kinh phí lớn nhất trong các cầu tại thành phố tính đến nay. Cầu dài gần 1,5 km, 6 làn xe, thiết kế dây văng với trụ tháp chính nghiêng về Thủ Thiêm, tạo điểm nhấn kiến trúc nổi bật trên sông Sài Gòn.','Còn cầu Thủ Thiêm 1 nối đường Ngô Tất Tố, Nguyễn Hữu Cảnh (quận Bình Thạnh) đến tuyến Nguyễn Cơ Thạch trong Khu đô thị Thủ Thiêm, được đổi tên lại thành Thủ Thiêm. Công trình này đã đưa vào khai thác từ năm 2008 với chiều dài hơn 1,2 km, 6 làn xe, tổng kinh phí đầu tư hơn 1.000 tỷ đồng.','Tên mới của hai cầu được HĐND TP HCM thông qua hồi tháng 12 năm ngoái. Theo Sở Văn hoá và Thể thao, Thủ Thiêm là tên gọi xuất hiện từ thế kỷ 18, đến nay địa danh này thuộc TP Thủ Đức. Thủ là đồn canh dưới thời phong kiến và cũng chỉ chức vụ đứng đầu một tổ chức hay đơn vị hành chính. Có thể người chỉ huy đồn binh tên Thêm nên dân gian quen gọi thành Thủ Thiêm.','Còn Ba Son là tên gọi từ năm 1790 khi chúa Nguyễn Ánh đặt trại thủy quân và xây dựng \"xưởng thủy\" bên bờ sông Sài Gòn. Ba Son được xem là cái nôi của ngành công nghiệp đóng và sửa chữa tàu thuỷ Việt Nam. Nơi đây trở thành phần quan trọng trong lịch sử đấu tranh giành độc lập dân tộc của Sài Gòn - TP HCM, gắn liền cuộc đời hoạt động của Chủ tịch Tôn Đức Thắng.','Phó chủ tịch UBND thành phố Dương Anh Đức cho biết việc sử dụng các tên gọi này cho hai cầu có ý nghĩa giáo dục truyền thống lịch sử, tạo sức hút thu hút đầu tư để thành phố sớm hoàn thành mục tiêu xây dựng Khu đô thị mới Thủ Thiêm. Các đơn vị liên quan cần làm tốt duy tu, bảo trì để hai công trình trở thành điểm nhấn cảnh quan đô thị của thành phố.','Theo quy hoạch, có 4 cây cầu và một hầm kết nối Khu đô thị mới Thủ Thiêm với trung tâm thành phố. Ngoài cầu Thủ Thiêm và Ba Son, hầm vượt sông Sài Gòn trên đại lộ Đông Tây nối quận 1 với khu đô thị này đã đưa vào khai thác cách đây 12 năm. Hai cầu còn lại gồm Thủ Thiêm 3 (nối quận 4) và Thủ Thiêm 4 (nối quận 7) chưa được đầu tư.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3719337769.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    a='Đường ống dầu khí nước sâu dài nhất Trung Quốc Trung Quốc hôm 22/6 hoàn thành lắp đặt đường ống nước sâu dài 115,5 km dùng để vận chuyển dầu khí.Đường ống mới lắp đặt là một phần quan trọng trong giai đoạn II của dự án giai đoạn xây trạm năng lượng siêu sâu dưới nước đầu tiên do Trung Quốc phát triển độc lập mang tên Shenhai-1, đi vào hoạt động từ tháng 6/2021, theo CGTN.\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "a='Đường ống dầu khí nước sâu dài nhất Trung Quốc Trung Quốc hôm 22/6 hoàn thành lắp đặt đường ống nước sâu dài 115,5 km dùng để vận chuyển dầu khí.Đường ống mới lắp đặt là một phần quan trọng trong giai đoạn II của dự án giai đoạn xây trạm năng lượng siêu sâu dưới nước đầu tiên do Trung Quốc phát triển độc lập mang tên Shenhai-1, đi vào hoạt động từ tháng 6/2021, theo CGTN.\n",
    "\n",
    "Giai đoạn II của dự án bắt đầu xây dựng vào tháng 11 năm ngoái, cách thành phố Tam Á trên đảo Hải Nam phía nam Trung Quốc 130 km, giữa mỏ khí Yacheng 13-1 và trạm năng lượng Shenhai-1. Độ sâu hoạt động tối đa trong khu vực là gần 1.000 m. Sau khi hoạt động, dự án giai đoạn II dự kiến sẽ tăng sản lượng tối đa hàng năm của Shenhai-1 từ 3 tỷ m3 lên 4,5 tỷ m3.\n",
    "\n",
    "Nhằm phát triển hiệu quả và tiết kiệm dự án giai đoạn II, Tập đoàn dầu khí ngoài khơi quốc gia Trung Quốc (CNOOC) tiên phong ứng dụng mô hình mới. Mô hình này bao gồm hệ thống sản xuất dưới biển, giàn xử lý chân đế nước nông và hệ thống điều khiển từ xa cho giàn khoan bán chìm nước sâu, theo Wu Hualin, phó giám đốc phụ trách cáp và đường ống ở dự án Shenhai-1 giai đoạn II tại chi nhánh Hải Nam của CNOOC.\n",
    "\n",
    "Đường ống dưới nước đóng vai trò như \"cứu cánh\" giúp đảm bảo vận chuyển dầu khí ngoài khơi trôi chảy. Dự án giai đoạn II tập trung vào mỏ khí áp suất cao nước sâu đầu tiên của Trung Quốc. Dầu khí khai thác từ mỏ có thành phần phức tạp, đồng thời chịu nhiệt độ và áp suất cao. Đường ống thông thường không thể đáp ứng các yêu cầu sản xuất.\n",
    "\n",
    "Vì vậy, CNOOC sử dụng biện pháp kết hợp 114 km đường ống thép liền mạch đường kính lớn và 1,5 km đường ống composite lưỡng kim trong môi trường nước sâu để vận chuyển dầu khí.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in a:\n",
    "    lines = gensim.utils.simple_preprocess(i)\n",
    "    lines = ' '.join(lines)\n",
    "    lines = ViTokenizer.tokenize(lines)\n",
    "    text.append(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hai cầu_nối khu đô_thị mới thủ thiêm có tên mới địa_danh ba son và thủ thiêm được đặt tên cho hai cầu_vượt sông sài_gòn nối trung_tâm thành_phố với khu đô_thị thủ thiêm sáng cầu_thủ thiêm kết_nối đường tôn đức thắng quận đến khu đô_thị mới được đặt tên ba son đây là công_trình biểu_tượng của tp hcm khánh_thành hồi tháng năm_ngoái với tổng vốn gần tỷ đồng kinh_phí lớn nhất trong các cầu tại thành_phố tính đến nay cầu dài gần km làn xe thiết_kế dây văng với trụ tháp chính nghiêng về thủ thiêm tạo điểm nhấn kiến_trúc nổi_bật trên sông sài_gòn còn cầu_thủ thiêm nối đường ngô tất_tố nguyễn hữu cảnh quận bình_thạnh đến tuyến nguyễn cơ thạch trong khu đô_thị thủ thiêm được đổi tên lại thành thủ thiêm công_trình này đã đưa vào khai_thác từ năm với chiều dài hơn km làn xe tổng kinh_phí đầu_tư hơn tỷ đồng tên mới của hai cầu được hđnd tp hcm thông_qua hồi tháng năm_ngoái theo sở văn_hoá và thể_thao thủ thiêm là tên gọi xuất_hiện từ thế_kỷ đến nay địa_danh này thuộc tp thủ đức thủ là đồn canh dưới thời phong_kiến và cũng chỉ chức_vụ đứng đầu một tổ_chức hay đơn_vị hành_chính có_thể người chỉ_huy đồn binh tên thêm nên dân_gian quen gọi thành thủ thiêm còn ba son là tên gọi từ năm khi chúa nguyễn ánh đặt trại thủy_quân và xây_dựng xưởng thủy bên bờ sông sài_gòn ba son được xem là cái nôi của ngành công_nghiệp đóng và sửa_chữa tàu_thuỷ việt nam nơi đây trở_thành_phần quan_trọng trong lịch_sử đấu_tranh_giành độc_lập dân_tộc của sài_gòn tp hcm gắn liền cuộc_đời hoạt_động của chủ_tịch tôn đức thắng phó_chủ_tịch ubnd thành_phố dương anh đức cho biết việc sử_dụng các tên gọi này cho hai cầu có_nghĩa giáo_dục truyền_thống lịch_sử tạo sức hút thu_hút đầu_tư để thành_phố sớm hoàn_thành mục_tiêu xây_dựng khu đô_thị mới thủ thiêm các đơn_vị liên_quan cần làm tốt duy_tu bảo_trì để hai công_trình trở_thành điểm nhấn cảnh_quan đô_thị của thành_phố theo quy_hoạch có cây cầu và một hầm kết_nối khu đô_thị mới thủ thiêm với trung_tâm thành_phố ngoài cầu_thủ thiêm và ba son hầm vượt sông sài_gòn trên đại_lộ đông tây nối quận với khu đô_thị này đã đưa vào khai_thác cách đây năm hai cầu còn lại gồm thủ thiêm nối quận và thủ thiêm nối quận chưa được đầu_tư'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = ' '.join(text)\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_2 = [\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "]\n",
    "for name, classifier2 in classifiers_2:\n",
    "    classifier2.fit(X_data_tfidf, y_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc =  tfidf_vect.transform(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 120352)\t0.019145828279886996\n",
      "  (0, 120266)\t0.08195749572427626\n",
      "  (0, 120020)\t0.030570581144502736\n",
      "  (0, 119949)\t0.026963194809330897\n",
      "  (0, 119626)\t0.028752944340438985\n",
      "  (0, 119620)\t0.07087962627709701\n",
      "  (0, 119205)\t0.09280257893115006\n",
      "  (0, 118767)\t0.05539963078960488\n",
      "  (0, 118653)\t0.012728899388569992\n",
      "  (0, 118633)\t0.06237121450908008\n",
      "  (0, 118352)\t0.042553818653679826\n",
      "  (0, 118149)\t0.031540168638940026\n",
      "  (0, 118103)\t0.039337073276804954\n",
      "  (0, 117914)\t0.018164990981430373\n",
      "  (0, 117868)\t0.22495372626097726\n",
      "  (0, 117842)\t0.021336160746920144\n",
      "  (0, 116141)\t0.0311455147008479\n",
      "  (0, 114075)\t0.038279491925675445\n",
      "  (0, 113720)\t0.0362907215217294\n",
      "  (0, 113484)\t0.020235379135851755\n",
      "  (0, 112873)\t0.04141574648442111\n",
      "  (0, 111115)\t0.020336113396506518\n",
      "  (0, 110528)\t0.04031603851869824\n",
      "  (0, 110441)\t0.04342848949904096\n",
      "  (0, 109401)\t0.016047370954550493\n",
      "  :\t:\n",
      "  (0, 26505)\t0.03468485832520955\n",
      "  (0, 26457)\t0.04096185093876899\n",
      "  (0, 26226)\t0.05269609439271566\n",
      "  (0, 22051)\t0.045199731544693374\n",
      "  (0, 22016)\t0.07213692888558709\n",
      "  (0, 22003)\t0.04127726788492384\n",
      "  (0, 21958)\t0.15482406136887214\n",
      "  (0, 21748)\t0.03746311230696962\n",
      "  (0, 21713)\t0.027249073984839525\n",
      "  (0, 20937)\t0.08071778935308115\n",
      "  (0, 20711)\t0.02535780397068062\n",
      "  (0, 20477)\t0.010421620111220394\n",
      "  (0, 20452)\t0.030603460048845992\n",
      "  (0, 19764)\t0.03068970608079532\n",
      "  (0, 17221)\t0.036541042952525374\n",
      "  (0, 17150)\t0.022176236392372133\n",
      "  (0, 16886)\t0.03283465151557386\n",
      "  (0, 16411)\t0.04195634533741004\n",
      "  (0, 15246)\t0.01999607319651123\n",
      "  (0, 13019)\t0.03759246988711103\n",
      "  (0, 12322)\t0.028532420046786168\n",
      "  (0, 11321)\t0.03883957842884526\n",
      "  (0, 10371)\t0.04654123508462248\n",
      "  (0, 7618)\t0.032626561642769614\n",
      "  (0, 7171)\t0.04263238266911744\n"
     ]
    }
   ],
   "source": [
    "print(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinhtrixahoi'], dtype='<U13')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = classifier2.predict(abc)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model():\n",
    "    input_layer = Input(shape=(300,))\n",
    "    layer = Reshape((10, 30))(input_layer)\n",
    "    layer = LSTM(128, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(128, activation='relu')(layer)\n",
    "    \n",
    "    output_layer = Dense(10, activation='softmax')(layer)\n",
    "    \n",
    "    classifier = models.Model(input_layer, output_layer)\n",
    "    \n",
    "    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "56/56 [==============================] - 13s 135ms/step - loss: 2.2732 - accuracy: 0.1170 - val_loss: 2.0360 - val_accuracy: 0.2202\n",
      "Epoch 2/3\n",
      "56/56 [==============================] - 6s 112ms/step - loss: 1.9179 - accuracy: 0.2585 - val_loss: 1.6449 - val_accuracy: 0.3720\n",
      "Epoch 3/3\n",
      "56/56 [==============================] - 8s 143ms/step - loss: 1.5335 - accuracy: 0.3975 - val_loss: 1.4076 - val_accuracy: 0.4639\n",
      "Test accuracy:  0.4698498094597624\n"
     ]
    }
   ],
   "source": [
    "classifier = create_lstm_model()\n",
    "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data_n, X_test=X_test_tfidf_svd, y_test=y_test_n, is_neuralnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dnn_model():\n",
    "    input_layer = Input(shape=(300,))\n",
    "    layer = Dense(1024, activation='relu')(input_layer)\n",
    "    layer = Dense(1024, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    output_layer = Dense(10, activation='softmax')(layer)\n",
    "    classifier = models.Model(input_layer, output_layer)\n",
    "    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "56/56 [==============================] - 11s 158ms/step - loss: 1.3675 - accuracy: 0.6320 - val_loss: 0.3342 - val_accuracy: 0.8906\n",
      "Epoch 2/3\n",
      "56/56 [==============================] - 8s 142ms/step - loss: 0.3108 - accuracy: 0.8955 - val_loss: 0.3045 - val_accuracy: 0.8946\n",
      "Epoch 3/3\n",
      "56/56 [==============================] - 8s 146ms/step - loss: 0.2551 - accuracy: 0.9123 - val_loss: 0.3040 - val_accuracy: 0.8960\n",
      "Test accuracy:  0.894754539340955\n"
     ]
    }
   ],
   "source": [
    "classifier = create_dnn_model()\n",
    "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data_n, X_test=X_test_tfidf_svd, y_test=y_test_n, is_neuralnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_model():\n",
    "    input_layer = Input(shape=(300,))\n",
    "    \n",
    "    layer = Reshape((10, 30))(input_layer)\n",
    "    layer = Bidirectional(GRU(128, activation='relu', return_sequences=True))(layer)    \n",
    "    layer = Convolution1D(100, 3, activation=\"relu\")(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(128, activation='relu')(layer)\n",
    "    \n",
    "    output_layer = Dense(10, activation='softmax')(layer)\n",
    "    \n",
    "    classifier = models.Model(input_layer, output_layer)\n",
    "    classifier.summary()\n",
    "    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 10, 256)           122880    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 8, 100)            76900     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               410112    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 939,502\n",
      "Trainable params: 939,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "56/56 [==============================] - 42s 399ms/step - loss: 2.0549 - accuracy: 0.2374 - val_loss: 0.7887 - val_accuracy: 0.7543\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 18s 316ms/step - loss: 0.6585 - accuracy: 0.7948 - val_loss: 0.4917 - val_accuracy: 0.8430\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 18s 321ms/step - loss: 0.4717 - accuracy: 0.8520 - val_loss: 0.4159 - val_accuracy: 0.8672\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 18s 321ms/step - loss: 0.4013 - accuracy: 0.8726 - val_loss: 0.3945 - val_accuracy: 0.8699\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 18s 327ms/step - loss: 0.3754 - accuracy: 0.8799 - val_loss: 0.3972 - val_accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 19s 335ms/step - loss: 0.3687 - accuracy: 0.8796 - val_loss: 0.3540 - val_accuracy: 0.8834\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 19s 330ms/step - loss: 0.3358 - accuracy: 0.8919 - val_loss: 0.3416 - val_accuracy: 0.8836\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 18s 319ms/step - loss: 0.3115 - accuracy: 0.8954 - val_loss: 0.3259 - val_accuracy: 0.8934\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 18s 314ms/step - loss: 0.2967 - accuracy: 0.8993 - val_loss: 0.3412 - val_accuracy: 0.8907\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 17s 310ms/step - loss: 0.2827 - accuracy: 0.9057 - val_loss: 0.3552 - val_accuracy: 0.8815\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 18s 315ms/step - loss: 0.2731 - accuracy: 0.9095 - val_loss: 0.3133 - val_accuracy: 0.8917\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 18s 320ms/step - loss: 0.2566 - accuracy: 0.9109 - val_loss: 0.3176 - val_accuracy: 0.8923\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 17s 312ms/step - loss: 0.2587 - accuracy: 0.9084 - val_loss: 0.3141 - val_accuracy: 0.8939\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 18s 314ms/step - loss: 0.2570 - accuracy: 0.9109 - val_loss: 0.3290 - val_accuracy: 0.8883\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 18s 318ms/step - loss: 0.2339 - accuracy: 0.9173 - val_loss: 0.3113 - val_accuracy: 0.8956\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 18s 318ms/step - loss: 0.2320 - accuracy: 0.9180 - val_loss: 0.3369 - val_accuracy: 0.8882\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 18s 322ms/step - loss: 0.2225 - accuracy: 0.9209 - val_loss: 0.3203 - val_accuracy: 0.8904\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 18s 319ms/step - loss: 0.2115 - accuracy: 0.9244 - val_loss: 0.3506 - val_accuracy: 0.8896\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 18s 322ms/step - loss: 0.2062 - accuracy: 0.9262 - val_loss: 0.3120 - val_accuracy: 0.8987\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 18s 318ms/step - loss: 0.1846 - accuracy: 0.9339 - val_loss: 0.3113 - val_accuracy: 0.8982\n",
      "Test accuracy:  0.9012553239184039\n"
     ]
    }
   ],
   "source": [
    "classifier = create_rcnn_model()\n",
    "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data_n, X_test=X_test_tfidf_svd, y_test=y_test_n, is_neuralnet=True, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
